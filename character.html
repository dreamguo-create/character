<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>想你的夜</title>
    <style>
        /* ================= 基础样式 (来自代码 B) ================= */
        body { 
            margin: 0; overflow: hidden; background-color: #050505; 
            font-family: 'Segoe UI', 'Courier New', sans-serif;
        }

        body::before {
            content: ""; position: absolute; top: 0; left: 0; width: 100%; height: 100%;
            background: radial-gradient(circle at center, #1a1a1a 0%, #000000 100%);
            z-index: 0;
        }

        canvas { display: block; position: relative; z-index: 1; }

        /* ================= 移植：赛博 HUD 摄像头界面 (来自代码 A) ================= */
        #hud-container {
            position: fixed; top: 20px; right: 20px; 
            width: 300px; height: 200px; /* 稍微调小一点以免遮挡太多 */
            z-index: 20;
            border: 2px solid #00f3ff;
            background: rgba(0, 0, 0, 0.8); border-radius: 4px; overflow: hidden;
            box-shadow: 0 0 20px rgba(0, 243, 255, 0.2);
            transition: all 0.3s;
        }
        /* 召唤时的特效 */
        #hud-container.active {
            border-color: #ff3366;
            box-shadow: 0 0 30px rgba(255, 51, 102, 0.5);
        }

        #input-video {
            display: block !important; position: absolute; top: 0; left: 0; width: 100%; height: 100%;
            object-fit: cover; transform: scaleX(-1); z-index: 1; opacity: 0.6;
        }

        #output-canvas {
            position: absolute; top: 0; left: 0; width: 100%; height: 100%;
            transform: scaleX(-1); z-index: 2; pointer-events: none;
        }

        #hud-overlay {
            position: absolute; top: 0; left: 0; width: 100%; height: 100%;
            background: linear-gradient(180deg, transparent 40%, rgba(0, 255, 255, 0.4) 50%, transparent 60%);
            background-size: 100% 300%;
            animation: scan 2s linear infinite;
            pointer-events: none; z-index: 3; mix-blend-mode: overlay;
        }
        @keyframes scan { 0% {background-position: 0% -300%;} 100% {background-position: 0% 0%;} }

        #hud-status-text {
            position: absolute; bottom: 0; left: 0; width: 100%;
            background: rgba(0, 20, 30, 0.9); border-top: 1px solid #00f3ff;
            color: #00f3ff; font-size: 10px; padding: 4px; text-align: center;
            letter-spacing: 2px; z-index: 4; font-weight: bold;
        }

        /* ================= UI 交互元素 (来自代码 B) ================= */
        #ui-container {
            position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%);
            text-align: center; z-index: 10; width: 100%;
            pointer-events: none;
        }

        .upload-zone {
            pointer-events: auto;
            display: inline-block;
            border: 2px dashed #00ffff;
            background: rgba(0, 255, 255, 0.1);
            padding: 40px 60px;
            border-radius: 20px;
            cursor: pointer;
            transition: 0.3s;
        }
        .upload-zone:hover { background: rgba(0, 255, 255, 0.2); box-shadow: 0 0 30px #00ffff; }
        .upload-text { color: #00ffff; font-size: 24px; font-weight: bold; letter-spacing: 2px; }
        .upload-sub { color: #888; margin-top: 10px; font-size: 14px; }
        input[type="file"] { display: none; }

        #bottom-bar {
            position: absolute; bottom: 30px; width: 100%; text-align: center; z-index: 10;
            pointer-events: none; opacity: 0; transition: opacity 1s;
        }
        .btn {
            pointer-events: auto;
            background: #222; border: 1px solid #fff; color: #fff;
            padding: 10px 25px; margin: 0 10px; cursor: pointer;
            font-size: 14px; border-radius: 30px; text-transform: uppercase;
        }
        .btn:hover { background: #fff; color: #000; }
        .btn-primary { border-color: #00ffff; color: #00ffff; }
        .btn-primary:hover { background: #00ffff; color: #000; box-shadow: 0 0 20px #00ffff; }

        #status {
            position: absolute; top: 20px; left: 20px; /* 移到左边避免遮挡 HUD */
            color: #fff; font-size: 18px; text-shadow: 0 0 10px #000; z-index: 10;
            display: none; font-weight: bold; letter-spacing: 1px;
        }
    </style>

    <!-- 核心库 -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <!-- 移植：使用 Holistic 库以支持面部和全身绘制 -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/control_utils/control_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/holistic/holistic.js"></script>
</head>
<body>

    <div id="status">HANDS DETECTED - FORMING IMAGE</div>

    <!-- 移植：HUD 容器 -->
    <div id="hud-container">
        <video id="input-video" playsinline autoplay></video>
        <canvas id="output-canvas"></canvas>
        <div id="hud-overlay"></div>
        <div id="hud-status-text">SYSTEM INITIALIZING...</div>
    </div>

    <!-- 初始上传界面 (代码 B) -->
    <div id="ui-container">
        <label class="upload-zone" id="drop-zone">
            <div class="upload-text">+ UPLOAD PHOTO</div>
            <div class="upload-sub">Select Image to Reassemble</div>
            <input type="file" id="imgInput" accept="image/*">
        </label>
    </div>

    <!-- 底部功能栏 (代码 B) -->
    <div id="bottom-bar">
        <button class="btn" onclick="toggleScatter()">Explode / Reset</button>
        <button class="btn btn-primary" onmousedown="forceSummon(true)" onmouseup="forceSummon(false)">
            Hold to Summon
        </button>
        <label class="btn">
            Change Photo <input type="file" id="imgInput2" accept="image/*" style="display:none">
        </label>
    </div>

    <script>
        // ==========================================
        // 第一部分：Three.js 粒子系统 (完全保留代码 B)
        // ==========================================
        
        const CONFIG = {
            particleSize: 0.55,     // 高保真实心粒子
            scanStep: 1,            // 高精度扫描
            depthStrength: 5.0,     // 适度深度
            lerpSpeed: 0.22,        // 响应速度
            scatterRange: 1000      // 爆炸范围
        };

        let scene, camera, renderer, particles, geometry;
        let isSummoning = false;
        let isImageLoaded = false;
      
        let particleSystem = {
            positions: [], targets: [], scatter: [], colors: [], count: 0
        };

        function initThree() {
            scene = new THREE.Scene();
            camera = new THREE.PerspectiveCamera(60, window.innerWidth/window.innerHeight, 0.1, 2000);
            camera.position.z = 150;

            renderer = new THREE.WebGLRenderer({antialias: true, alpha: true});
            renderer.setSize(window.innerWidth, window.innerHeight);
            renderer.setPixelRatio(window.devicePixelRatio);
            document.body.appendChild(renderer.domElement);

            animate();
        }

        function processImage(image) {
            if (particles) scene.remove(particles);

            const pos = [];
            const targets = [];
            const scatter = [];
            const cols = [];

            const canvas = document.createElement('canvas');
            const ctx = canvas.getContext('2d');
            const maxDimension = 300; 
            let w = image.width;
            let h = image.height;
            const aspect = w / h;

            if (w > maxDimension || h > maxDimension) {
                if (aspect > 1) { w = maxDimension; h = maxDimension / aspect; }
                else { h = maxDimension; w = maxDimension * aspect; }
            }
          
            canvas.width = w; canvas.height = h;
            ctx.drawImage(image, 0, 0, w, h);
            const imgData = ctx.getImageData(0, 0, w, h).data;

            for (let y = 0; y < h; y += CONFIG.scanStep) {
                for (let x = 0; x < w; x += CONFIG.scanStep) {
                    const i = (Math.floor(y) * Math.floor(w) + Math.floor(x)) * 4;
                    const r = imgData[i] / 255;
                    const g = imgData[i+1] / 255;
                    const b = imgData[i+2] / 255;
                    const a = imgData[i+3];

                    if (a > 20) {
                        cols.push(r, g, b);
                        const tx = (x - w/2);
                        const ty = -(y - h/2);
                        const bright = (r+g+b)/3;
                        const tz = bright * CONFIG.depthStrength;

                        targets.push(tx, ty, tz);
                        scatter.push(
                            (Math.random()-0.5) * CONFIG.scatterRange * 1.5,
                            (Math.random()-0.5) * CONFIG.scatterRange,
                            (Math.random()-0.5) * CONFIG.scatterRange
                        );
                        pos.push(scatter[scatter.length-3], scatter[scatter.length-2], scatter[scatter.length-1]);
                    }
                }
            }

            particleSystem.count = pos.length / 3;
            particleSystem.positions = new Float32Array(pos);
            particleSystem.targets = new Float32Array(targets);
            particleSystem.scatter = new Float32Array(scatter);
            particleSystem.colors = new Float32Array(cols);

            geometry = new THREE.BufferGeometry();
            geometry.setAttribute('position', new THREE.BufferAttribute(particleSystem.positions, 3));
            geometry.setAttribute('color', new THREE.BufferAttribute(particleSystem.colors, 3));

            const material = new THREE.PointsMaterial({
                size: CONFIG.particleSize, 
                vertexColors: true,
                transparent: false, 
                opacity: 1.0,
                sizeAttenuation: true,
                blending: THREE.NormalBlending 
            });

            particles = new THREE.Points(geometry, material);
            scene.add(particles);

            document.getElementById('ui-container').style.display = 'none';
            document.getElementById('bottom-bar').style.opacity = '1';
            document.getElementById('status').style.display = 'block';
            isImageLoaded = true;
        }

        function animate() {
            requestAnimationFrame(animate);
            if (!particles || !isImageLoaded) return;

            const pos = geometry.attributes.position.array;
            const dest = isSummoning ? particleSystem.targets : particleSystem.scatter;
            const count = particleSystem.count;

            for (let i = 0; i < count; i++) {
                const idx = i * 3;
                pos[idx]   += (dest[idx] - pos[idx]) * CONFIG.lerpSpeed;
                pos[idx+1] += (dest[idx+1] - pos[idx+1]) * CONFIG.lerpSpeed;
                pos[idx+2] += (dest[idx+2] - pos[idx+2]) * CONFIG.lerpSpeed;
            }

            geometry.attributes.position.needsUpdate = true;
            
            const time = Date.now() * 0.001;
            if (isSummoning) {
                particles.rotation.y = Math.sin(time) * 0.1; 
                particles.rotation.x = Math.cos(time * 0.8) * 0.05;
            } else {
                particles.rotation.y += 0.002;
            }
            renderer.render(scene, camera);
        }

        // ==========================================
        // 第二部分：交互与事件 (代码 B 逻辑)
        // ==========================================

        function handleFile(e) {
            const file = e.target.files[0];
            if(!file) return;
            const reader = new FileReader();
            reader.onload = (event) => {
                const img = new Image();
                img.onload = () => processImage(img);
                img.src = event.target.result;
            };
            reader.readAsDataURL(file);
        }

        document.getElementById('imgInput').addEventListener('change', handleFile);
        document.getElementById('imgInput2').addEventListener('change', handleFile);

        window.forceSummon = (bool) => { isSummoning = bool; updateStatusText(); };
        window.toggleScatter = () => { isSummoning = false; updateStatusText(); };

        function updateStatusText() {
            const el = document.getElementById('status');
            const hudText = document.getElementById('hud-status-text');
            const hudBox = document.getElementById('hud-container');

            if (isSummoning) {
                el.innerText = ">>> SUMMONING ACTIVE <<<";
                el.style.color = "#00ffff";
                hudText.innerText = "TARGET LOCKED | REASSEMBLING...";
                hudText.style.color = "#ff3366";
                hudBox.classList.add("active");
            } else {
                el.innerText = "STATUS: SCATTERED";
                el.style.color = "#888";
                hudText.innerText = "SCANNING FOR GESTURES...";
                hudText.style.color = "#00f3ff";
                hudBox.classList.remove("active");
            }
        }

        // ==========================================
        // 第三部分：AI 视觉系统 (移植自代码 A)
        // ==========================================
        
        const videoEl = document.getElementById('input-video');
        const canvasEl = document.getElementById('output-canvas');
        const ctxEl = canvasEl.getContext('2d');

        function onResults(results) {
            // 1. 绘制 HUD (来自代码 A 的视觉效果)
            canvasEl.width = videoEl.videoWidth; 
            canvasEl.height = videoEl.videoHeight;
            ctxEl.save();
            ctxEl.clearRect(0, 0, canvasEl.width, canvasEl.height);
          
            const lineStyle = {color: '#00f3ff', lineWidth: 2};
            const faceStyle = {color: 'rgba(0, 243, 255, 0.1)', lineWidth: 1};
            const handStyle = {color: '#ff3366', lineWidth: 2};

            // 绘制面部网格、姿态连线、手部连线
            drawConnectors(ctxEl, results.faceLandmarks, FACEMESH_TESSELATION, faceStyle);
            drawConnectors(ctxEl, results.poseLandmarks, POSE_CONNECTIONS, lineStyle);
            drawConnectors(ctxEl, results.leftHandLandmarks, HAND_CONNECTIONS, handStyle);
            drawConnectors(ctxEl, results.rightHandLandmarks, HAND_CONNECTIONS, handStyle);
            ctxEl.restore();

            // 2. 逻辑判断 (将代码 B 的手势逻辑应用到代码 A 的数据结构上)
            if (!isImageLoaded) return;

            // 检测是否有两只手
            if (results.leftHandLandmarks && results.rightHandLandmarks) {
                // 计算两手拇指尖的距离 (索引 4)
                const lx = results.leftHandLandmarks[4].x;
                const ly = results.leftHandLandmarks[4].y;
                const rx = results.rightHandLandmarks[4].x;
                const ry = results.rightHandLandmarks[4].y;
                
                const dist = Math.hypot(lx - rx, ly - ry);

                // 阈值判断 (MediaPipe 坐标是归一化的 0-1)
                if (dist < 0.2) {
                    isSummoning = true;
                } else {
                    isSummoning = false;
                }
            } else {
                // 单手或无手 -> 散开
                isSummoning = false;
            }
            updateStatusText();
        }

        // 初始化 Holistic 模型 (比单纯的 Hands 模型更酷，带面部网格)
        const holistic = new Holistic({locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/holistic/${file}`});
        holistic.setOptions({
            modelComplexity: 1, 
            smoothLandmarks: true,
            minDetectionConfidence: 0.6, 
            minTrackingConfidence: 0.6
        });
        holistic.onResults(onResults);

        const cameraAI = new Camera(videoEl, {
            onFrame: async () => { await holistic.send({image: videoEl}); },
            width: 480, height: 360 // 降低一点分辨率以提高性能
        });
        
        // 启动
        cameraAI.start().then(() => {
            document.getElementById('hud-status-text').innerText = "OPTICAL SENSORS ONLINE";
        });

        window.addEventListener('resize', () => {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        });

        initThree();
    </script>
</body>
</html>
